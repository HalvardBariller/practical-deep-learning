{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "4jVkOWmgFT1p"
   },
   "source": [
    "# **Practical session on Transfer Learning**\n",
    "This Pratical session proposes to study several techniques for improving challenging context, in which few data and resources are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "QLKnIngy_2hg"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "**Context :**\n",
    "\n",
    "Assume we are in a context where few \"gold\" labeled data are available for training, say \n",
    "\n",
    "$$\\mathcal{X}_{\\text{train}} = \\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$$\n",
    "\n",
    "where $N_{\\text{train}}$ is small. \n",
    "\n",
    "A large test set $\\mathcal{X}_{\\text{test}}$ as well as a large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
    "\n",
    "**Instructions to follow :** \n",
    "\n",
    "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question :\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   XXX  | XXX | XXX | XXX |\n",
    "\n",
    "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset!)\n",
    "\n",
    "In your final report, please *keep the logs of each training procedure* you used. We will only run this jupyter if we have some doubts on your implementation. \n",
    "\n",
    "The total file sizes should be reasonable (feasible with 2MB only!). You will be asked to hand in the notebook, together with any necessary files required to run it if any.\n",
    "\n",
    "You can use https://colab.research.google.com/ to run your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "YmTCQPSh_2hg"
   },
   "source": [
    "## Training set creation\n",
    "__Question 1 (1 points) :__ Propose a dataloader to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set.\n",
    "\n",
    "Additional information :  \n",
    "\n",
    "*   CIFAR10 dataset : https://en.wikipedia.org/wiki/CIFAR-10\n",
    "*   You can directly use the dataloader framework from Pytorch.\n",
    "*   Alternatively you can modify the file : https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "uZkC5IxR_2hh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=True, download=True, transform=transforms.ToTensor())\n",
    "train_subset = torch.utils.data.Subset(train_dataset, indices=range(100)) \n",
    "train_loader = torch.utils.data.DataLoader(train_subset)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "fUno1nmu_2hh"
   },
   "source": [
    "* This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project. \n",
    "\n",
    "* The remaining samples correspond to $\\mathcal{X}$. \n",
    "\n",
    "* The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "Vr0d4o5L_2hi"
   },
   "source": [
    "## Testing procedure\n",
    "__Question 2 (0.5 points):__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "ppiTrnpd_2hi"
   },
   "source": [
    "Evaluating the training procedure presents challenges stemming from several factors:\n",
    "\n",
    "1. **Limited Training Dataset Size**:\n",
    "    With just 100 samples selected from a pool of 50,000 training images, there's an inherent imbalance in class representation. This discrepancy can lead to certain classes being underrepresented, potentially skewing the model's understanding. Even while avoiding the extreme scenario of omitting entire classes from training, ensuring a balanced representation remains crucial.\n",
    "\n",
    "    To address this issue, careful selection of data samples is imperative. We must ensure that the chosen samples adequately represent the various classes present in the CIFAR-10 dataset. Resampling techniques offer a solution by either downsampling or oversampling data. Methods such as RandomUnderSampler and RandomOverSampler, available in libraries like imbalanced-learn, can help rectify class imbalances, fostering a more equitable training environment.\n",
    "\n",
    "2. **Proneness to Overfitting**:\n",
    "    Training on a small dataset heightens the risk of overfitting, wherein the model memorizes training samples rather than generalizing patterns. Consequently, performance on the test dataset may suffer, as the model struggles to extrapolate beyond its narrow training scope.\n",
    "\n",
    "    Data augmentation techniques can artificially expand the training dataset by applying transformations like rotation, scaling, and flipping to existing samples, fostering robustness and diversity in the model's learning process. Additionally, leveraging weak supervision techniques can augment the labeled dataset. Methods such as semi-supervised and self-supervised learning enable the utilization of unlabeled data, expanding the training dataset and potentially enhancing model performance. By iteratively labeling subsets of unlabeled data and incorporating them into training, we can enrich the model's understanding and mitigate the limitations imposed by a constrained training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "OEaIwILB_2hi"
   },
   "source": [
    "# The Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "M-PQZ2Vl_2hi"
   },
   "source": [
    "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performance with reported numbers from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
    "\n",
    "The key ingredients for training a CNN are the batch size, as well as the learning rate scheduler (i.e. how to decrease the learning rate as a function of the number of epochs). A possible scheduler is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the learning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
    "\n",
    "You can get some baselines accuracies in this paper (obviously, it is a different context for those researchers who had access to GPUs!) : http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "ARHWPXrY_2hi"
   },
   "source": [
    "## ResNet architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "voMbGoNw_2hj"
   },
   "source": [
    "__Question 3 (2 points) :__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1512.03385). Please report the accuracy obtained on the whole dataset as well as the reference paper/GitHub link.\n",
    "\n",
    "*Hint :* You can re-use the following code : https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40% accuracy on $\\mathcal{X}_{\\text{train}}$ (\\~2 minutes) and 20% accuracy on $\\mathcal{X}_{\\text{test}}$ (\\~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "RVHhKmWN_2hj"
   },
   "outputs": [],
   "source": [
    "# Source of the following code: https://github.com/kuangliu/pytorch-cifar\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, data_loader, loss_fn, opt, device, is_train=True, scheduler=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Runs a training or evaluation epoch.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train or evaluate.\n",
    "        data_loader (torch.utils.data.DataLoader): The DataLoader for input data.\n",
    "        loss_fn (callable): The loss function.\n",
    "        opt (torch.optim.Optimizer): The optimizer for training.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        is_train (bool): Specifies if the model should be in training mode.\n",
    "        scheduler (torch.optim.lr_scheduler, optional): Learning rate scheduler.\n",
    "        verbose (bool): If True, prints progress using tqdm.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Mean loss and accuracy for the epoch.\n",
    "    \"\"\"\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(data_loader, disable=not verbose):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            if is_train:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    mean_loss = total_loss / len(data_loader.dataset)\n",
    "    mean_accuracy = total_corrects.double() / len(data_loader.dataset)\n",
    "    \n",
    "    return mean_loss, mean_accuracy\n",
    "\n",
    "def train_and_test(model, train_loader, test_loader, loss_fn, opt, device, epochs=10, scheduler=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train and evaluate.\n",
    "        train_loader (torch.utils.data.DataLoader): The DataLoader for training data.\n",
    "        test_loader (torch.utils.data.DataLoader): The DataLoader for test data.\n",
    "        loss_fn (callable): The loss function.\n",
    "        opt (torch.optim.Optimizer): The optimizer for training.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        epochs (int): Number of training epochs.\n",
    "        scheduler (torch.optim.lr_scheduler, optional): Learning rate scheduler.\n",
    "        verbose (bool): If True, prints progress and results.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing training and test losses and accuracies.\n",
    "    \"\"\"\n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if verbose: print(f'Epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        # Run training epoch\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, loss_fn, opt, device, is_train=True, scheduler=scheduler, verbose=verbose)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Run evaluation epoch\n",
    "        test_loss, test_acc = run_epoch(model, test_loader, loss_fn, opt, device, is_train=False, verbose=verbose)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "    if verbose: print('Finished Training')\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 128.60it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.9490, Train Acc: 0.1700, Test Loss: 7.5198, Test Acc: 0.0739\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 132.51it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.3874, Train Acc: 0.2000, Test Loss: 4.6420, Test Acc: 0.0539\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 134.58it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.9685, Train Acc: 0.3200, Test Loss: 3.0744, Test Acc: 0.1863\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.64it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 1.6861, Train Acc: 0.4000, Test Loss: 2.3786, Test Acc: 0.1979\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 132.98it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.6251, Train Acc: 0.4400, Test Loss: 2.2361, Test Acc: 0.2048\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.51it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.5448, Train Acc: 0.5000, Test Loss: 2.1725, Test Acc: 0.2123\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.47it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.5778, Train Acc: 0.5000, Test Loss: 2.1736, Test Acc: 0.2141\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.13it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.4665, Train Acc: 0.5400, Test Loss: 2.1674, Test Acc: 0.2137\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.45it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.4893, Train Acc: 0.5200, Test Loss: 2.1694, Test Acc: 0.2140\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.62it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 69.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.4314, Train Acc: 0.5900, Test Loss: 2.1615, Test Acc: 0.2151\n",
      "Finished Training\n",
      "Test loss: 2.1615, Test accuracy: 0.2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=True, download=True, transform=transforms.ToTensor())\n",
    "train_subset = torch.utils.data.Subset(train_dataset, indices=range(100)) \n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=False, download=True, transform=transforms.ToTensor())\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False) # for faster computation\n",
    "\n",
    "# Prepare the model, device, optimizer, scheduler, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and test the model\n",
    "history = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, epochs=epochs, scheduler=scheduler)\n",
    "\n",
    "# Print test results from the history\n",
    "last_epoch_results = f\"Test loss: {history['test_loss'][-1]:.4f}, Test accuracy: {history['test_acc'][-1]:.4f}\"\n",
    "print(last_epoch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   ResNet18  | 10 | 59.00% | 21.51% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "8Tn9pW14_2hj"
   },
   "source": [
    "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "z8g_3ZDi_2hj"
   },
   "source": [
    "## ImageNet features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "PfYEhdFb_2hj"
   },
   "source": [
    "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on : https://pytorch.org/vision/stable/models.html.\n",
    "\n",
    "__Question 4 (1 points):__ Pick a model from the list above, adapt it for CIFAR10 and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "collapsed": true,
    "id": "i_lh4xje_2hk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 128.49it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.9863, Train Acc: 0.2200, Test Loss: 2.7933, Test Acc: 0.1611\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 139.04it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.1128, Train Acc: 0.4000, Test Loss: 2.7232, Test Acc: 0.1986\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 138.43it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.3159, Train Acc: 0.5800, Test Loss: 3.2238, Test Acc: 0.2184\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 137.91it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.9146, Train Acc: 0.6500, Test Loss: 2.6006, Test Acc: 0.2548\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 136.07it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.7688, Train Acc: 0.7400, Test Loss: 2.5253, Test Acc: 0.2528\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 135.63it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.6539, Train Acc: 0.7800, Test Loss: 2.5575, Test Acc: 0.2581\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 135.89it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.7191, Train Acc: 0.7500, Test Loss: 2.5289, Test Acc: 0.2625\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 134.29it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.5063, Train Acc: 0.8400, Test Loss: 2.5284, Test Acc: 0.2604\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 135.99it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.5110, Train Acc: 0.8500, Test Loss: 2.5487, Test Acc: 0.2646\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 135.76it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.5808, Train Acc: 0.8400, Test Loss: 2.5397, Test Acc: 0.2636\n",
      "Finished Training\n",
      "Test loss: 2.5397, Test accuracy: 0.2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights # We chose the ResNet18 for comparison sake\n",
    "\n",
    "# Define hyperparameters\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=True, download=True, transform=transforms.ToTensor())\n",
    "train_subset = torch.utils.data.Subset(train_dataset, indices=range(100)) \n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"\\content\", train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Prepare the model, device, optimizer, scheduler, and loss function\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model with the best available weights\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights).to(device)\n",
    "# Adapt it for CIFAR10\n",
    "model.fc = nn.Linear(512, 10).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and test the model\n",
    "history = train_and_test(model, train_loader, test_loader, criterion, optimizer, device, epochs=epochs, scheduler=scheduler)\n",
    "\n",
    "# Print test results from the history\n",
    "last_epoch_results = f\"Test loss: {history['test_loss'][-1]:.4f}, Test accuracy: {history['test_acc'][-1]:.4f}\"\n",
    "print(last_epoch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   Pre-trained ResNet18  | 10 | 84.00% | 26.36% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "SvkuMzLs_2hk"
   },
   "source": [
    "# Incorporating *a priori*\n",
    "Geometrical *a priori* are appealing for image classification tasks, though one might have to handle several boundary effects.\n",
    "\n",
    "__Question 5 (0.5 points) :__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "TIaY60o1_2hk"
   },
   "source": [
    "When dealing with translations, rotations, scaling effects, and color changes on 32x32 images, several issues may arise:\n",
    "\n",
    "- **Loss of Information**: These transformations can potentially lead to a loss of important information in the image, especially when dealing with rotations or scaling effects. This loss of information can hinder the model's ability to learn meaningful features from the data.\n",
    "\n",
    "- **Boundary Artifacts**: Translations, rotations, and scaling effects can result in boundary artifacts, where parts of the image may be cut off or distorted, particularly along the edges of the image.\n",
    "\n",
    "- **Aliasing**: When scaling down or rotating images, aliasing artifacts may occur, leading to a loss of image quality and introducing unwanted high-frequency noise.\n",
    "\n",
    "- **Color Distortion**: Changes in color, brightness, or contrast can alter the appearance of objects in the image, potentially making it difficult for the model to generalize across different color distributions.\n",
    "\n",
    "\n",
    "\n",
    "To tackle these issues, several ideas can be considered:\n",
    "\n",
    "- **Padding**: Apply padding to the image before performing transformations to mitigate boundary artifacts. Padding ensures that no information is lost at the edges of the image during transformations.\n",
    "\n",
    "- **Interpolation**: Use appropriate interpolation methods when scaling images to reduce aliasing artifacts and maintain image quality.\n",
    "\n",
    "- **Normalization**: Normalize the color channels of the images to a standard range before applying color changes. This can help ensure that color transformations do not disproportionately affect certain channels or introduce unrealistic color distributions.\n",
    "\n",
    "- **Quality Control**: Regularly inspect augmented images to ensure that transformations are applied appropriately and do not introduce unrealistic variations or distortions that could adversely affect model performance.\n",
    "\n",
    "- **Data Augmentation**: Augment the training data with a diverse set of transformations, but ensure that the transformations are applied judiciously to avoid excessive distortion or loss of information. For example, limit the range of rotation angles or scaling factors to retain semantic content. We could even consider **Adaptive Augmentation**: Apply data augmentation techniques adaptively based on the specific characteristics of the dataset. For instance, consider applying less aggressive transformations to images with complex content or fine details. Finally, **Domain-specific Augmentation**: Tailor data augmentation techniques to the characteristics of the target domain. For example, when dealing with medical images, consider incorporating domain-specific knowledge to guide the augmentation process and ensure that clinically relevant features are preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "ds6e6teG_2hk"
   },
   "source": [
    "## Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "-Ek5wlOo_2hk"
   },
   "source": [
    "__Question 6 (4 points):__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ with them and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "collapsed": true,
    "id": "FqCjrXGk_2hk"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'deep-env2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n deep-env2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "HRUA5I8N_2hk"
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "RmyiWAPJ_2hl"
   },
   "source": [
    "__Question 7 (3 points) :__ Write a short report explaining the pros and the cons of each method that you implemented. 25% of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "zJ-v4Nev_2hl"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "sAGp7ddN_2hl"
   },
   "source": [
    "# Weak supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "wHQRLbC3_2hl"
   },
   "source": [
    "__Bonus \\[open\\] question (up to 3 points) :__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "GUk74Ejgac/t",
    "id": "rbjhfIvN_2hl"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kfiletag": "GUk74Ejgac/t",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
